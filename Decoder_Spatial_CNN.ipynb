{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "import time\n",
    "from random import shuffle\n",
    "import pandas as pd \n",
    "import spectral\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import scipy\n",
    "import IndianPinesCNN\n",
    "#import seaborn as sns\n",
    "from collections import Counter\n",
    "import Spatial_dataset as input_data\n",
    "import patch_size\n",
    "import os\n",
    "#print IndianPinesCNN.IMAGE_PIXELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as io\n",
    "DATA_PATH = os.path.join(os.getcwd(),\"Data\")\n",
    "input_image = scipy.io.loadmat(os.path.join(DATA_PATH, \"Indian_pines.mat\"))['indian_pines']\n",
    "output_image = scipy.io.loadmat(os.path.join(DATA_PATH, \"Indian_pines_gt.mat\"))['indian_pines_gt']\n",
    "\n",
    "model_name = 'model-spatial-11X11.ckpt-3999'\n",
    "# input_image = np.rot90(input_image)\n",
    "# output_image = np.rot90(output_image)\n",
    "height = output_image.shape[0]\n",
    "width = output_image.shape[1]\n",
    "PATCH_SIZE = patch_size.patch_size\n",
    "batch_size = 100\n",
    "num_examples = 800\n",
    "\n",
    "conv1 = 500\n",
    "conv2 = 100\n",
    "fc1 = 200\n",
    "fc2 = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Scaling Down the image to 0 - 1\n",
    "\n",
    "input_image = input_image.astype(float)\n",
    "input_image -= np.min(input_image)\n",
    "input_image /= np.max(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_array(data):\n",
    "    mean_arr = []\n",
    "    for i in range(data.shape[0]):\n",
    "        mean_arr.append(np.mean(data[i,:,:]))\n",
    "    return np.array(mean_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Patch(data,height_index,width_index):\n",
    "    transpose_array = data.transpose((2,0,1))\n",
    "    #print transpose_array.shape\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    patch = transpose_array[:, height_slice, width_slice]\n",
    "    #print patch.shape\n",
    "    mean = mean_array(transpose_array)\n",
    "    mean_patch = []\n",
    "    for i in range(patch.shape[0]):\n",
    "        mean_patch.append(patch[i] - mean[i])\n",
    "    mean_patch = np.asarray(mean_patch)\n",
    "    patch = mean_patch.transpose((1,2,0))\n",
    "    patch = patch.reshape(-1,patch.shape[0]*patch.shape[1]*patch.shape[2])\n",
    "    #print patch.shape\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def placeholder_inputs(batch_size):\n",
    "    \"\"\"Generate placeholder variables to represent the input tensors.\n",
    "    These placeholders are used as inputs by the rest of the model building\n",
    "    code and will be fed from the downloaded data in the .run() loop, below.\n",
    "    Args:\n",
    "    batch_size: The batch size will be baked into both placeholders.\n",
    "    Returns:\n",
    "    images_placeholder: Images placeholder.\n",
    "    labels_placeholder: Labels placeholder.\n",
    "    \"\"\"\n",
    "    # Note that the shapes of the placeholders match the shapes of the full\n",
    "    # image and label tensors, except the first dimension is now batch_size\n",
    "    # rather than the full size of the train or test data sets.\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(batch_size, IndianPinesCNN\n",
    "                                                           .IMAGE_PIXELS))\n",
    "    labels_placeholder = tf.placeholder(tf.int32, shape=(batch_size))\n",
    "    return images_placeholder, labels_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_feed_dict(data_set, images_pl, labels_pl):\n",
    "    \"\"\"Fills the feed_dict for training the given step.\n",
    "    A feed_dict takes the form of:\n",
    "    feed_dict = {\n",
    "      <placeholder>: <tensor of values to be passed for placeholder>,\n",
    "      ....\n",
    "    }\n",
    "    Args:\n",
    "    data_set: The set of images and labels, from input_data.read_data_sets()\n",
    "    images_pl: The images placeholder, from placeholder_inputs().\n",
    "    labels_pl: The labels placeholder, from placeholder_inputs().\n",
    "    Returns:\n",
    "    feed_dict: The feed dictionary mapping from placeholders to values.\n",
    "    \"\"\"\n",
    "    # Create the feed_dict for the placeholders filled with the next\n",
    "    # `batch size ` examples.\n",
    "    images_feed, labels_feed = data_set.next_batch(batch_size)\n",
    "    feed_dict = {\n",
    "      images_pl: images_feed,\n",
    "      labels_pl: labels_feed,\n",
    "    }\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_eval(sess,\n",
    "            eval_correct,\n",
    "            images_placeholder,\n",
    "            labels_placeholder,\n",
    "            data_set):\n",
    "    \"\"\"Runs one evaluation against the full epoch of data.\n",
    "    Args:\n",
    "    sess: The session in which the model has been trained.\n",
    "    eval_correct: The Tensor that returns the number of correct predictions.\n",
    "    images_placeholder: The images placeholder.\n",
    "    labels_placeholder: The labels placeholder.\n",
    "    data_set: The set of images and labels to evaluate, from\n",
    "      input_data.read_data_sets().\n",
    "    \"\"\"\n",
    "    # And run one epoch of eval.\n",
    "    true_count = 0  # Counts the number of correct predictions.\n",
    "    steps_per_epoch = data_set.num_examples // batch_size\n",
    "    num_examples = steps_per_epoch * batch_size\n",
    "    for step in xrange(steps_per_epoch):\n",
    "        feed_dict = fill_feed_dict(data_set,\n",
    "                                   images_placeholder,\n",
    "                                   labels_placeholder)\n",
    "        true_count += sess.run(eval_correct, feed_dict=feed_dict)\n",
    "    precision = float(true_count) / num_examples\n",
    "    print('  Num examples: %d  Num correct: %d  Precision @ 1: %0.04f' %\n",
    "        (num_examples, true_count, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoder():\n",
    "    \n",
    "    #data_sets = input_data.read_data_sets('Test1.mat','test')\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        images_placeholder, labels_placeholder = placeholder_inputs(1)\n",
    "\n",
    "        logits = IndianPinesCNN.inference(images_placeholder,\n",
    "                                 conv1,\n",
    "                                 conv2,        \n",
    "                                 fc1,\n",
    "                                 fc2)\n",
    "        \n",
    "        eval_correct = IndianPinesCNN.evaluation(logits, labels_placeholder)\n",
    "        \n",
    "        sm = tf.nn.softmax(logits)\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        sess = tf.Session()\n",
    "        \n",
    "        saver.restore(sess,model_name)\n",
    "        \n",
    "        temp = []\n",
    "\n",
    "        outputs = np.zeros((height,width))\n",
    "        predicted_results = [[0 for i in range(width)]for x in range(height)]\n",
    "        for i in range(height-PATCH_SIZE+1):\n",
    "            for j in range(width-PATCH_SIZE+1):\n",
    "                target = int(output_image[i+PATCH_SIZE/2, j+PATCH_SIZE/2])\n",
    "                if target == 0 :\n",
    "                    continue\n",
    "                else :\n",
    "                    image_patch=Patch(input_image,i,j)\n",
    "                    #print image_patch\n",
    "                    prediction = sess.run(sm, feed_dict = {images_placeholder:image_patch})\n",
    "                    #print prediction\n",
    "                    temp1 = np.argmax(prediction)+1\n",
    "                    #print temp1\n",
    "                    outputs[i+PATCH_SIZE/2][j+PATCH_SIZE/2] = temp1\n",
    "                    predicted_results[i+PATCH_SIZE/2][j+PATCH_SIZE/2] = prediction\n",
    "                    \n",
    "    return outputs,predicted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image,predicted_results = decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ground_truth = spectral.imshow(classes = output_image,figsize =(5,5))\n",
    "predict_image = spectral.imshow(classes = predicted_image.astype(int),figsize =(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f_out = open('Predictions.pkl','ab')\n",
    "# pkl.dump({'11x11_aug':predicted_results}, f_out)\n",
    "# f_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
