{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains and Evaluates the IndianPines network using a feed dictionary\n",
    "========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import IndianPinesCNN \n",
    "import patch_size\n",
    "# import IndianPines_data_set as input_data\n",
    "import Spatial_dataset as input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare model parameters as external flags\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('max_steps', 4000, 'Number of steps to run trainer.')\n",
    "flags.DEFINE_integer('conv1', 500, 'Number of filters in convolutional layer 1.')\n",
    "flags.DEFINE_integer('conv2', 100, 'Number of filters in convolutional layer 2.')\n",
    "flags.DEFINE_integer('hidden1', 200, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 84, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_integer('batch_size', 100, 'Batch size.  '\n",
    "                     'Must divide evenly into the dataset sizes.')\n",
    "# flags.DEFINE_string('train_dir', '1.mat', 'Directory to put the training data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 20\n",
    "max_steps = 4000\n",
    "IMAGE_SIZE = patch_size.patch_size\n",
    "conv1 = 500\n",
    "conv2 = 100\n",
    "fc1 = 200,\n",
    "fc2 = 84\n",
    "batch_size = 100\n",
    "TRAIN_FILES = 8\n",
    "TEST_FILES = 6\n",
    "DATA_PATH = os.path.join(os.getcwd(),\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def placeholder_inputs(batch_size):\n",
    "    \"\"\"Generate placeholder variables to represent the input tensors.\n",
    "    These placeholders are used as inputs by the rest of the model building\n",
    "    code and will be fed from the downloaded data in the .run() loop, below.\n",
    "    Args:\n",
    "    batch_size: The batch size will be baked into both placeholders.\n",
    "    Returns:\n",
    "    images_placeholder: Images placeholder.\n",
    "    labels_placeholder: Labels placeholder.\n",
    "    \"\"\"\n",
    "    # Note that the shapes of the placeholders match the shapes of the full\n",
    "    # image and label tensors, except the first dimension is now batch_size\n",
    "    # rather than the full size of the train or test data sets.\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(batch_size, IndianPinesCNN\n",
    "                                                           .IMAGE_PIXELS))\n",
    "    labels_placeholder = tf.placeholder(tf.int32, shape=(batch_size))\n",
    "    return images_placeholder, labels_placeholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_feed_dict(data_set, images_pl, labels_pl):\n",
    "    \"\"\"Fills the feed_dict for training the given step.\n",
    "    A feed_dict takes the form of:\n",
    "    feed_dict = {\n",
    "      <placeholder>: <tensor of values to be passed for placeholder>,\n",
    "      ....\n",
    "    }\n",
    "    Args:\n",
    "    data_set: The set of images and labels, from input_data.read_data_sets()\n",
    "    images_pl: The images placeholder, from placeholder_inputs().\n",
    "    labels_pl: The labels placeholder, from placeholder_inputs().\n",
    "    Returns:\n",
    "    feed_dict: The feed dictionary mapping from placeholders to values.\n",
    "    \"\"\"\n",
    "    # Create the feed_dict for the placeholders filled with the next\n",
    "    # `batch size ` examples.\n",
    "    images_feed, labels_feed = data_set.next_batch(batch_size)\n",
    "    feed_dict = {\n",
    "      images_pl: images_feed,\n",
    "      labels_pl: labels_feed,\n",
    "    }\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_eval(sess,\n",
    "            eval_correct,\n",
    "            images_placeholder,\n",
    "            labels_placeholder,\n",
    "            data_set):\n",
    "    \"\"\"Runs one evaluation against the full epoch of data.\n",
    "    Args:\n",
    "    sess: The session in which the model has been trained.\n",
    "    eval_correct: The Tensor that returns the number of correct predictions.\n",
    "    images_placeholder: The images placeholder.\n",
    "    labels_placeholder: The labels placeholder.\n",
    "    data_set: The set of images and labels to evaluate, from\n",
    "      input_data.read_data_sets().\n",
    "    \"\"\"\n",
    "    # And run one epoch of eval.\n",
    "    true_count = 0  # Counts the number of correct predictions.\n",
    "    steps_per_epoch = data_set.num_examples // batch_size\n",
    "    num_examples = steps_per_epoch * batch_size\n",
    "    for step in xrange(steps_per_epoch):\n",
    "        feed_dict = fill_feed_dict(data_set,\n",
    "                                   images_placeholder,\n",
    "                                   labels_placeholder)\n",
    "        true_count += sess.run(eval_correct, feed_dict=feed_dict)\n",
    "    precision = true_count / num_examples\n",
    "    print('  Num examples: %d  Num correct: %d  Precision @ 1: %0.04f' %\n",
    "        (num_examples, true_count, precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_DataSet(first,second):\n",
    "    temp_image = np.concatenate((first.images,second.images),axis=0)\n",
    "    temp_labels = np.concatenate((first.labels,second.labels),axis=0)\n",
    "    temp_image = temp_image.reshape(temp_image.shape[0],IMAGE_SIZE,IMAGE_SIZE,220)\n",
    "    temp_image = np.transpose(temp_image,(0,3,1,2))\n",
    "    temp_labels = np.transpose(temp_labels)\n",
    "    return input_data.DataSet(temp_image,temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    \"\"\"Train MNIST for a number of steps.\"\"\"\n",
    "    # Get the sets of images and labels for training, validation, and\n",
    "    # test on IndianPines.\n",
    "    \n",
    "    \"\"\"Concatenating all the training and test mat files\"\"\"\n",
    "    for i in range(TRAIN_FILES):\n",
    "        data_sets = input_data.read_data_sets(os.path.join(DATA_PATH, 'Train_'+str(IMAGE_SIZE)+'_'+str(i+1)+'.mat'), 'train')\n",
    "        if(i==0):\n",
    "            Training_data = data_sets\n",
    "            continue\n",
    "        else:\n",
    "            Training_data = add_DataSet(Training_data,data_sets)\n",
    "            \n",
    "    for i in range(TEST_FILES):\n",
    "        data_sets = input_data.read_data_sets(os.path.join(DATA_PATH, 'Test_'+str(IMAGE_SIZE)+'_'+str(i+1)+'.mat'),'test')\n",
    "        if(i==0):\n",
    "            Test_data = data_sets\n",
    "            continue\n",
    "        else:\n",
    "            Test_data = add_DataSet(Test_data,data_sets)\n",
    "        \n",
    "    # Tell TensorFlow that the model will be built into the default Graph.\n",
    "    with tf.Graph().as_default():\n",
    "    # Generate placeholders for the images and labels.\n",
    "        images_placeholder, labels_placeholder = placeholder_inputs(FLAGS.batch_size)\n",
    "\n",
    "        # Build a Graph that computes predictions from the inference model.\n",
    "        logits = IndianPinesCNN.inference(images_placeholder,\n",
    "                                 FLAGS.conv1,\n",
    "                                 FLAGS.conv2,        \n",
    "                                 FLAGS.hidden1,\n",
    "                                 FLAGS.hidden2)\n",
    "\n",
    "        # Add to the Graph the Ops for loss calculation.\n",
    "        loss = IndianPinesCNN.loss(logits, labels_placeholder)\n",
    "\n",
    "        # Add to the Graph the Ops that calculate and apply gradients.\n",
    "        train_op = IndianPinesCNN.training(loss, FLAGS.learning_rate)\n",
    "\n",
    "        # Add the Op to compare the logits to the labels during evaluation.\n",
    "        eval_correct = IndianPinesCNN.evaluation(logits, labels_placeholder)\n",
    "\n",
    "        # Build the summary operation based on the TF collection of Summaries.\n",
    "    #    summary_op = tf.merge_all_summaries()\n",
    "\n",
    "        # Add the variable initializer Op.\n",
    "        init = tf.initialize_all_variables()\n",
    "\n",
    "        # Create a saver for writing training checkpoints.\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Create a session for running Ops on the Graph.\n",
    "        sess = tf.Session()\n",
    "\n",
    "        # Instantiate a SummaryWriter to output summaries and the Graph.\n",
    "    #    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph)\n",
    "\n",
    "        # And then after everything is built:\n",
    "\n",
    "        # Run the Op to initialize the variables.\n",
    "        sess.run(init)\n",
    "\n",
    "        # Start the training loop.\n",
    "        for step in xrange(FLAGS.max_steps):\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Fill a feed dictionary with the actual set of images and labels\n",
    "            # for this particular training step.\n",
    "            feed_dict = fill_feed_dict(Training_data,\n",
    "                                     images_placeholder,\n",
    "                                     labels_placeholder)\n",
    "\n",
    "            # Run one step of the model.  The return values are the activations\n",
    "            # from the `train_op` (which is discarded) and the `loss` Op.  To\n",
    "            # inspect the values of your Ops or variables, you may include them\n",
    "            # in the list passed to sess.run() and the value tensors will be\n",
    "            # returned in the tuple from the call.\n",
    "            _, loss_value = sess.run([train_op, loss],\n",
    "                                   feed_dict=feed_dict)\n",
    "\n",
    "            duration = time.time() - start_time\n",
    "\n",
    "            # Write the summaries and print an overview fairly often.\n",
    "            if step % 50 == 0:\n",
    "            # Print status to stdout.\n",
    "                print('Step %d: loss = %.2f (%.3f sec)' % (step, loss_value, duration))\n",
    "            # Update the events file.\n",
    "    #             summary_str = sess.run(summary_op, feed_dict=feed_dict)\n",
    "    #             summary_writer.add_summary(summary_str, step)\n",
    "    #             summary_writer.flush()\n",
    "\n",
    "            # Save a checkpoint and evaluate the model periodically.\n",
    "            if (step + 1) % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n",
    "                saver.save(sess, os.getcwd()+'\\model-spatial-CNN-'+str(IMAGE_SIZE)+'X'+str(IMAGE_SIZE)+'.ckpt', global_step=step)\n",
    "\n",
    "            # Evaluate against the training set.\n",
    "                print('Training Data Eval:')\n",
    "                do_eval(sess,\n",
    "                        eval_correct,\n",
    "                        images_placeholder,\n",
    "                        labels_placeholder,\n",
    "                        Training_data)\n",
    "                print('Test Data Eval:')\n",
    "                do_eval(sess,\n",
    "                        eval_correct,\n",
    "                        images_placeholder,\n",
    "                        labels_placeholder,\n",
    "                        Test_data)\n",
    "            # Evaluate against the validation set.\n",
    "    #             print('Validation Data Eval:')\n",
    "    #             do_eval(sess,\n",
    "    #                     eval_correct,\n",
    "    #                     images_placeholder,\n",
    "    #                     labels_placeholder,\n",
    "    #                     data_sets.validation)\n",
    "    #             # Evaluate against the test set.\n",
    "    #             print('Test Data Eval:')\n",
    "    #             do_eval(sess,\n",
    "    #                     eval_correct,\n",
    "    #                     images_placeholder,\n",
    "    #                     labels_placeholder,\n",
    "    #                     data_sets.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-0683f80cdbe4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-626474ea7185>\u001b[0m in \u001b[0;36mrun_training\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;34m\"\"\"Concatenating all the training and test mat files\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN_FILES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mdata_sets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Train_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mTraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Desktop\\Hyperspectral\\Spatial_dataset.py\u001b[0m in \u001b[0;36mread_data_sets\u001b[1;34m(directory, value, dtype)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_patch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mdata_sets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexh_000\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[0mMR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mmdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatfile_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexh_000\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\scipy\\io\\matlab\\mio5.py\u001b[0m in \u001b[0;36mget_variables\u001b[1;34m(self, variable_names)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_var_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhdr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mMatReadError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 warnings.warn(\n",
      "\u001b[1;32mc:\\users\\alexh_000\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\scipy\\io\\matlab\\mio5.py\u001b[0m in \u001b[0;36mread_var_array\u001b[1;34m(self, header, process)\u001b[0m\n\u001b[0;32m    250\u001b[0m            \u001b[0;31m`\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         '''\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matrix_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_from_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mscipy\\io\\matlab\\mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab.mio5_utils.VarReader5.array_from_header (scipy\\io\\matlab\\mio5_utils.c:7578)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mscipy\\io\\matlab\\mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab.mio5_utils.VarReader5.array_from_header (scipy\\io\\matlab\\mio5_utils.c:6575)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mscipy\\io\\matlab\\mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab.mio5_utils.VarReader5.read_real_complex (scipy\\io\\matlab\\mio5_utils.c:8049)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mscipy\\io\\matlab\\mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab.mio5_utils.VarReader5.read_numeric (scipy\\io\\matlab\\mio5_utils.c:4575)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mscipy\\io\\matlab\\mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab.mio5_utils.VarReader5.read_element (scipy\\io\\matlab\\mio5_utils.c:4143)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mscipy\\io\\matlab\\streams.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab.streams.GenericStream.read_string (scipy\\io\\matlab\\streams.c:2430)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mscipy\\io\\matlab\\pyalloc.pxd\u001b[0m in \u001b[0;36mscipy.io.matlab.pyalloc.pyalloc_v (scipy\\io\\matlab\\streams.c:6000)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Desktop\\Hyperspectral\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
